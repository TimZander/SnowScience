{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from MesoPy import Meso\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#place inside ~/.bashrc\n",
    "#export mesokey='key'\n",
    "m=Meso(token=os.environ['mesokey'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Goal is to limit to just one observation a day. Air temp high and low we can likely just take from a specific slot\n",
    "#perhaps the first\n",
    "\n",
    "import pandas as pd\n",
    "df_snow = pd.read_csv('../data/CAICVailSummitDangerScale.csv')\n",
    "df_snow=df_snow.drop_duplicates(subset='date')\n",
    "df_snow = df_snow.set_index('date')\n",
    "#df_weather = pd.read_csv('weather.csv')\n",
    "df_weather_date = pd.read_csv('weather_date.csv')\n",
    "df_weather_date = df_weather_date.drop_duplicates()\n",
    "df_weather_date = df_snow.join(df_weather_date.set_index('date'))\n",
    "df_weather_date = df_weather_date.set_index('datetime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not found 2013-12-22\n",
      "not found 2014-06-29\n",
      "not found 2014-11-18\n",
      "not found 2015-04-21\n",
      "not found 2015-05-06\n",
      "not found 2015-11-01\n",
      "not found 2015-11-12\n",
      "not found 2016-04-24\n",
      "not found 2016-05-25\n",
      "not found 2016-10-12\n",
      "not found 2016-10-18\n",
      "not found 2016-11-21\n"
     ]
    }
   ],
   "source": [
    "columns = ['datetime', \n",
    "           'yesterday_air_temp_low_24_hour',\n",
    "           'yesterday_air_temp_high_24_hour', \n",
    "           'yesterday_precip_accum_24_hour',\n",
    "           'yesterday_rating_above',\n",
    "           'yesterday_rating_near',\n",
    "           'yesterday_rating_below']\n",
    "df_y = pd.DataFrame(data=np.zeros((0,len(columns))), columns=columns)\n",
    "for index, row in df_weather_date.iterrows():\n",
    "    y_date = pd.to_datetime(index)-pd.DateOffset(1)\n",
    "    y_date = y_date.date().strftime('%Y-%m-%d')\n",
    "    #help(y_date)\n",
    "    #print(y_date.date(), index)\n",
    "    #break\n",
    "    try:\n",
    "        y=df_weather_date.loc[y_date]\n",
    "        if(y.shape==(2,7)):\n",
    "            print(y_date)\n",
    "        df_y = df_y.append({'datetime': index, \n",
    "                            'yesterday_air_temp_low_24_hour':y['air_temp_low_24_hour'], \n",
    "                            'yesterday_air_temp_high_24_hour': y['air_temp_high_24_hour'], \n",
    "                            'yesterday_precip_accum_24_hour':y['precip_accum_24_hour'],\n",
    "                            'yesterday_rating_above': y['rating_today_above'],\n",
    "                            'yesterday_rating_near': y['rating_today_near'],\n",
    "                            'yesterday_rating_below': y['rating_today_below']}, ignore_index=True)\n",
    "    except:\n",
    "        print(\"not found\", y_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_run = df_weather_date.join(df_y.set_index('datetime'))\n",
    "df_clean = df_run.dropna(axis=0, how='any')\n",
    "df=df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "X, Y = df.iloc[:,3:].values, df.iloc[:, 2].values\n",
    "X_train, X_test, Y_train, Y_test = \\\n",
    "    train_test_split(X, Y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.preprocessing as pp\n",
    "#help(pp)\n",
    "stdsc = pp.StandardScaler()\n",
    "X_train_std = stdsc.fit_transform(X_train)\n",
    "X_test_std = stdsc.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy:  0.776836158192\n",
      "test accuracy:  0.789473684211\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "LogisticRegression(penalty='l1')\n",
    "lr=LogisticRegression(penalty='l1', C=0.1)\n",
    "lr.fit(X_train_std, Y_train)\n",
    "print('train accuracy: ', lr.score(X_train_std, Y_train))\n",
    "print('test accuracy: ', lr.score(X_test_std, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        , -0.3011213 ,  0.        , -1.91896911])"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.coef_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
